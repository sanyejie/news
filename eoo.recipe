#!/usr/bin/env python
# vim:fileencoding=utf-8
import os
import time
from calibre.web.feeds.news import BasicNewsRecipe


class EooNews(BasicNewsRecipe):
    title = u'经济观察报'
    description = u'经观报新闻'
    language = 'zh'
    encoding = 'UTF-8'

    no_stylesheets = True
    remove_javascript = True
    delay = 1
    extra_css = 'p {text-indent: 1.2em;} \n .btcbig {font-weight: 600;font-size:1.2em;}'
    max_articles_per_feed = 5 #篇数，默认100篇
    #oldest_article = 1 #天数，默认7天
    recursions = 1
    #max_articles_per_feed = 5
    #ignore_duplicate_articles = {'url', 'title'}
    #keep_only_tags = [dict(class_=['a-content-top','t-neirong t_box_public'])]
    #remove_tags = [dict(name=['img'])] #dict中可以dict(name='h1')，dict(id='footer')
    remove_tags_before  = dict(name='div', class_=['contact'])
    remove_tags_after  = dict(name='div', class_=['t-bottom content-center'])
    #remove_tags = [
    #    dict(id='comments'),
    #    dict(class_=['wsw__embed', 'share--box'])]

    feeds = {
        'Home': 'http://m.eeo.com.cn',
    }

    def parse_index(self):
        ans = []
        for topic, url in self.feeds.items():
            articles = []
            #new = self.get_page_content(url).find_all('div',attrs={'class':'a-news'})[7]
            #if new:
            #for new in news:
            content = self.get_page_content(url)
            if content:
                #items = content.find('div',attrs={'class':'marquee'}).findAll('a')
                #for a in items:
                    #a = item.find('a', href=True)
                #    if a:
                        #print "URL: ",a
                #        url=a['href']
                #        title=self.tag_to_string(a).strip()
                #        articles.append(dict(title=title, url=url))
                items = content.find('ul',attrs={'class':'xd-gcj5-div-ul'}).findAll('a')
                for a in items:
                    #a = item.find('a', href=True)
                    if a:
                        #print "URL: ",a
                        url=a['href']
                        title=self.tag_to_string(a).strip()
                        articles.append(dict(title=title, url=url))
            if len(articles) > 0:
                ans.append((topic, articles))
        return ans

    def get_page_content(self, url):
        try:
            return self.index_to_soup(url)
        except Exception as e:
            self.log.error('Fetch article failed(%s): %s' % (e, url))
